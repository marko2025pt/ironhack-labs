# Customer Churn Prediction – Project Report

## 1. Summary of Approach

The goal of this project was to predict customer churn for a telecommunications company using the Telco Customer Churn dataset. The dataset contains **7,043 customers** with 21 features, including demographics, service subscriptions, and account information. The target variable is `Churn` (Yes/No).

**Data Preprocessing Steps:**
1. **Check for missing values:** `TotalCharges` had 11 missing entries, which were dropped to ensure clean data. Other columns had no missing values.
2. **Convert numeric features:** `TotalCharges` was originally a string; it was converted to numeric.
3. **Target conversion:** `Churn` was mapped to binary (No → 0, Yes → 1) for classification.
4. **Binary categorical features:** Columns like `Partner`, `Dependents`, `PhoneService`, and `PaperlessBilling` were converted to 0/1.
5. **Multi-class categorical features:** Columns with more than 2 categories (e.g., `Contract`, `InternetService`, `PaymentMethod`) were one-hot encoded.
6. **Separate features and target:** Features (`X`) contained 30 numeric columns, and the target (`y`) contained the binary churn labels.

**Modeling Approach:**
- A **K-Nearest Neighbors (KNN)** classifier was used.
- The dataset was split into **training (80%)** and **testing (20%)** sets using stratification to maintain class distribution.
- We experimented with different `K` values to evaluate their impact on model performance, focusing on **accuracy, precision, and recall**.

---

## 2. Model Performance Metrics

### Initial KNN Model (K=5)
- **Training Accuracy:** 83.25%  
- **Test Accuracy:** 74.63%  
- **Precision (test):** 0.528  
- **Recall (test):** 0.428  

**Confusion Matrix (Test Set):**

|           | Predicted No | Predicted Yes |
|-----------|-------------|---------------|
| Actual No | 890         | 143           |
| Actual Yes| 214         | 160           |

**Interpretation:**  
- The model correctly predicts most non-churners but misses a significant portion of churners.
- Precision is moderate, indicating some false positives.
- Recall is relatively low, meaning many churners are not captured.

### K Experimentation
- Tested K = 1, 3, 5, …, 33.
- **Best Accuracy & Precision:** K = 31  
- **Best Recall:** K = 1  

**Insights:**
- Higher K → more stable predictions, fewer false alarms, higher precision.
- Lower K → more sensitive to churners, higher recall.

---

## 3. Key Findings About Customer Churn

1. **Imbalanced dataset:** ~74% of customers do not churn, ~26% do. This affects model performance, particularly recall.
2. **Numerical patterns:** 
   - Churners have **lower tenure** (mean ≈ 18 months) compared to non-churners (mean ≈ 38 months).  
   - Churners have **higher monthly charges** (mean ≈ $74) than non-churners (mean ≈ $61).  
3. **Categorical patterns:** 
   - Month-to-month contracts, electronic payment methods, and lack of additional services are more common among churners.

---

## 4. Business Recommendations

1. **Focus retention efforts on high-risk customers:**
   - Customers with month-to-month contracts, higher monthly charges, or low tenure.
   - Targeted incentives or service improvements could reduce churn.
2. **Balance between recall and precision:**
   - If the priority is **catching as many churners as possible**, use K = 1 (higher recall).  
   - If the priority is **avoiding false alerts**, use K = 31 (higher precision).
3. **Monitor and adapt:** Continuously retrain models as customer behavior changes.

---

## 5. Limitations and Future Improvements

1. **Data Imbalance:** The model may underpredict churners due to the imbalance. Techniques like **SMOTE** or **class weighting** could improve recall.
2. **Feature engineering:** Additional features (e.g., customer service interactions, complaints) may enhance predictive power.
3. **Model complexity:** KNN is simple; more advanced models like **Random Forests, Gradient Boosting, or Neural Networks** could provide better performance.
4. **Temporal patterns:** Churn may depend on trends over time; time-series or sequential models could capture this.
5. **Business integration:** Thresholds for classification should align with cost-benefit analysis for retention strategies.

**Conclusion:**  
Our analysis shows that churn can be reasonably predicted using KNN, but business priorities (catching churners vs. avoiding false alerts) strongly influence model selection. Further work on feature engineering, advanced models, and imbalance handling is recommended to improve practical deployment.
